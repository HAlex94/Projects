{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "7458b773-867e-593c-9acc-889ba8d59ea2",
        "openai_ephemeral_user_id": "57242abd-6158-52e5-ac33-a7c9b2f4a0ec"
      }
    },
    "noteable": {
      "last_transaction_id": "f87cea50-e8e0-4a0e-b97c-5c206702792c"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "header_cell",
      "cell_type": "markdown",
      "source": "# Diabetes Prediction Analysis\n\nThis notebook presents an analysis of a diabetes prediction dataset. The dataset includes medical and demographic data from patients, along with their diabetes status (positive or negative). The data includes features such as age, gender, body mass index (BMI), hypertension, heart disease, smoking history, HbA1c level, and blood glucose level.\n\nThe goal of this analysis is to scrutinize the dataset, perform exploratory data analysis, identify patterns, insights, outliers, and correlations, and generate a comprehensive report on the findings. Furthermore, we aim to create a machine learning model to predict whether a patient will have diabetes based on these criteria. We will use the scikit-learn library to test different models and TensorFlow to create a neural network model to classify the data. The performance of these models will be compared and visualized.\n\nDataset:https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "028261a6-2127-48e5-b5f9-07bdcf5133b9",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "88c22e2a-4f45-422b-9f6b-e4e440e98ba1"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:35:25.488528+00:00",
          "start_time": "2023-07-18T15:35:19.924046+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install tensorflow",
      "outputs": []
    },
    {
      "id": "2198573e-3484-4761-a881-a045343c74c7",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "33252854-689b-4e06-8437-cbb87141d1b0"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:35:32.923636+00:00",
          "start_time": "2023-07-18T15:35:30.121812+00:00"
        },
        "datalink": {
          "aa637f7f-f5cd-42df-9cdf-cf626fff893c": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 9,
              "orig_num_rows": 5,
              "orig_size_bytes": 400,
              "truncated_num_cols": 9,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 400,
              "truncated_string_columns": []
            },
            "display_id": "aa637f7f-f5cd-42df-9cdf-cf626fff893c",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-07-18T15:35:32.764938",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_74d97ae367e046a48ee0b85f0f32ac00"
          }
        }
      },
      "execution_count": null,
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Load the dataset\ndf = pd.read_csv('diabetes_prediction_dataset.csv')\ndf.head()",
      "outputs": []
    },
    {
      "id": "3cac2622-072c-4cff-a44e-a297ef74bb4a",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a0bf6cff-e39d-4d79-97fc-1b549102655b"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:36:44.438239+00:00",
          "start_time": "2023-07-18T15:36:44.212273+00:00"
        },
        "datalink": {
          "2419c131-e5bc-48ba-874f-883feee27428": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 1,
              "orig_num_rows": 9,
              "orig_size_bytes": 144,
              "truncated_num_cols": 1,
              "truncated_num_rows": 9,
              "truncated_size_bytes": 144,
              "truncated_string_columns": []
            },
            "display_id": "2419c131-e5bc-48ba-874f-883feee27428",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-07-18T15:36:44.281812",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_d88f3a531eda4c4d8e074fbc850295fe"
          }
        }
      },
      "execution_count": null,
      "source": "# Check for missing values\ndf.isnull().sum()",
      "outputs": []
    },
    {
      "id": "4c247a9b-0b36-4b21-974c-1f3281679e25",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "2df42f03-6d92-4f58-8d81-058018bad36d"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:37:06.807507+00:00",
          "start_time": "2023-07-18T15:37:06.562250+00:00"
        },
        "datalink": {
          "ba11d766-f7dc-49b4-aade-4dac8e624259": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 7,
              "orig_num_rows": 8,
              "orig_size_bytes": 512,
              "truncated_num_cols": 7,
              "truncated_num_rows": 8,
              "truncated_size_bytes": 512,
              "truncated_string_columns": []
            },
            "display_id": "ba11d766-f7dc-49b4-aade-4dac8e624259",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-07-18T15:37:06.649466",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_955625ba22e64bc1bcccacd43c14cdd6"
          }
        }
      },
      "execution_count": null,
      "source": "# Exploratory Data Analysis\ndf.describe()",
      "outputs": []
    },
    {
      "id": "a9d3e8dc-d0a1-42fe-b32d-02d8368d5ec1",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "62a359be-d6c2-47de-80c1-63324b62b1b2"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:37:53.762934+00:00",
          "start_time": "2023-07-18T15:37:52.783870+00:00"
        }
      },
      "execution_count": null,
      "source": "# Visualize the data\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix of Features')",
      "outputs": []
    },
    {
      "id": "f3110620-c570-4e1d-835d-c29916b7bfa5",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "7305aa8e-6b7b-422b-a3b4-5ea4443cd1f1"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:38:25.472276+00:00",
          "start_time": "2023-07-18T15:38:25.227740+00:00"
        }
      },
      "execution_count": null,
      "source": "from sklearn.preprocessing import LabelEncoder\n\n# Encode categorical variables\nle = LabelEncoder()\ndf['gender'] = le.fit_transform(df['gender'])\ndf['smoking_history'] = le.fit_transform(df['smoking_history'])\n\n# Split the data into training and testing sets\nX = df.drop('diabetes', axis=1)\ny = df['diabetes']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)",
      "outputs": []
    },
    {
      "id": "a898d3f6-0603-4206-8a14-220a676f3b01",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f0661cec-b43b-4daa-95a9-67c3c7407626"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:40:27.293218+00:00",
          "start_time": "2023-07-18T15:39:00.211759+00:00"
        }
      },
      "execution_count": null,
      "source": "# Initialize the models\nlog_reg = LogisticRegression()\nknn = KNeighborsClassifier()\nsvm = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\n\n# Train and evaluate the models\nmodels = [log_reg, knn, svm, dt, rf]\nmodel_names = ['Logistic Regression', 'K-Nearest Neighbors', 'Support Vector Machine', 'Decision Tree', 'Random Forest']\naccuracy_scores = []\n\nfor model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_scores.append(accuracy)\n\n# Display the accuracy scores\nfor i in range(len(models)):\n    print(f'{model_names[i]} Accuracy: {accuracy_scores[i] * 100:.2f}%')",
      "outputs": []
    },
    {
      "id": "3d4ede2a-d27f-48f3-8d97-ff46f5e46bdc",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "5d8620d8-67f9-4c06-85b7-0f057a194c5f"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:51:03.707582+00:00",
          "start_time": "2023-07-18T15:44:18.758986+00:00"
        }
      },
      "execution_count": null,
      "source": "# Initialize the neural network model\nmodel = keras.Sequential([\n    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n    keras.layers.Dense(16, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Neural Network Accuracy: {accuracy * 100:.2f}%')",
      "outputs": []
    },
    {
      "id": "75393796-2cde-4fde-838a-802629f96160",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "c9509742-09f5-4a6c-98d8-c87a577f7544"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T15:52:22.362100+00:00",
          "start_time": "2023-07-18T15:52:21.814963+00:00"
        }
      },
      "execution_count": null,
      "source": "# Add the accuracy of the neural network model to the list\nmodel_names.append('Neural Network')\naccuracy_scores.append(accuracy)\n\n# Create a DataFrame to store the accuracy scores\ndf_scores = pd.DataFrame({'Model': model_names, 'Accuracy': accuracy_scores})\n\n# Create a bar chart to compare the accuracy of the models\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Accuracy', y='Model', data=df_scores, palette='Blues_d')\nplt.title('Model Comparison - Accuracy')\nplt.xlabel('Accuracy')\nplt.ylabel('Model')",
      "outputs": []
    },
    {
      "id": "557020fc-3ec8-44c0-8b35-0a1086284283",
      "cell_type": "markdown",
      "source": "## Comparison Analysis for Top 3 Models\n\nThe top 3 models based on accuracy are Random Forest, Neural Network, and Support Vector Machine. Let's perform a more detailed comparison of these models. We will generate and compare the confusion matrix and classification report for each model.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "3e86bff6-cb61-452e-8baa-f97ca1244006",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4b23c2ba-b79f-480f-ba18-bb6793eb1257"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T16:39:52.800285+00:00",
          "start_time": "2023-07-18T16:39:39.052047+00:00"
        }
      },
      "execution_count": null,
      "source": "# Generate and print the confusion matrix and classification report for each model\ntop_models = [rf, svm, model]\ntop_model_names = ['Random Forest', 'Support Vector Machine', 'Neural Network']\n\nfor i in range(len(top_models)):\n    if top_model_names[i] == 'Neural Network':\n        y_pred = np.round(top_models[i].predict(X_test))\n    else:\n        y_pred = top_models[i].predict(X_test)\n\n    print(f'{top_model_names[i]}:')\n    print('Confusion Matrix:')\n    print(confusion_matrix(y_test, y_pred))\n    print('Classification Report:')\n    print(classification_report(y_test, y_pred))\n    print('-' * 60)",
      "outputs": []
    },
    {
      "id": "baee9a85-e424-4961-9dfc-c46eb854d511",
      "cell_type": "markdown",
      "source": "\nLet's visualize the confusion matrices for the top 3 models to better understand their performance.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "7ee75c7f-92fc-4ef7-abe7-3bd57a0470cf",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "7d003bca-3e27-44c3-b098-af4aa1f21819"
        },
        "ExecuteTime": {
          "end_time": "2023-07-18T16:41:39.246960+00:00",
          "start_time": "2023-07-18T16:41:24.612118+00:00"
        }
      },
      "execution_count": null,
      "source": "from sklearn.metrics import plot_confusion_matrix\n\n# Plot confusion matrices for the top models\nfig, axs = plt.subplots(1, 3, figsize=(20, 5))\n\nfor i, model in enumerate(top_models[:-1]):  # Exclude the Neural Network model for now\n    plot_confusion_matrix(model, X_test, y_test, ax=axs[i], cmap='Blues')\n    axs[i].set_title(top_model_names[i])\n\n# For the Neural Network model, we need to use a different method to plot the confusion matrix\ny_pred_nn = np.round(top_models[-1].predict(X_test))\ncm_nn = confusion_matrix(y_test, y_pred_nn)\nsns.heatmap(cm_nn, annot=True, fmt='d', cmap='Blues', ax=axs[-1])\naxs[-1].set_title(top_model_names[-1])\naxs[-1].set_xlabel('Predicted label')\naxs[-1].set_ylabel('True label')",
      "outputs": []
    },
    {
      "id": "conclusion_cell",
      "cell_type": "markdown",
      "source": "# Conclusion\n\nThis analysis involved the examination of a diabetes prediction dataset and the creation of machine learning models to predict the likelihood of diabetes based on various medical and demographic factors.\n\nThe dataset first underwent exploratory data analysis, where we identified patterns, insights, outliers, and correlations. The data was then prepared for machine learning by encoding categorical variables and splitting it into training and testing sets. The data was also scaled to ensure that all features have a similar range of values.\n\nWe trained various machine learning models, including Logistic Regression, K-Nearest Neighbors, Support Vector Machine, Decision Tree, and Random Forest. We also created a neural network model using TensorFlow. The performance of these models was evaluated and compared. The Random Forest model performed the best with an accuracy of 97.00%, followed closely by the Neural Network model with an accuracy of 96.86%.\n\nIn conclusion, the models we've trained could be used to predict whether a patient is likely to have diabetes based on their medical history and demographic information. However, it's important to note that these models should be used as a tool to assist healthcare professionals, not replace their judgment. The choice of model may depend on the specific needs of the application. If it is more important to correctly identify all positive cases (even at the risk of some false positives), the Random Forest or Neural Network models may be preferable. If it is more important to avoid false positives, the Support Vector Machine may be a better choice.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ]
}